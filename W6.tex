 

\documentclass[11pt,a4paper]{article}

%\input{symbols.tex}
\usepackage{amssymb}
\usepackage{german}
\usepackage{rawfonts}
\usepackage[dvips]{epsfig}
%\usepackage[dvips]{graphicx}
%\usepackage[pdftex]{graphicx}
\sloppy
\parindent0em
\parskip0.2em
%\topmargin-1.3 cm
%\textheight26cm
%\textwidth16.8cm
%%\oddsidemargin-0.5cm
%\oddsidemargin-1.5cm

\newenvironment{simplechar}{%
   \catcode`\$=12
   \catcode`\&=12
   \catcode`\#=12
   \catcode`\^=12
   \catcode`\_=12
   \catcode`\~=12
   \catcode`\%=12
}{}

\pagestyle{empty}

%\include{prepictex}
%\include{pictex}
%\include{postpictex}

\font \sfbold=cmssbx10


%\input{ISDSWorkshops/almS2w}

\begin{document}

%\head{5}{}

\setcounter{section}{1}

%\setcounter{aufg}{0}

%\rule{\textwidth}{0.03cm}
%\parskip0.6cm

In this document, we'll focus on using \texttt{R} to generate simple linear regression models, using the \texttt{lm} function. We will see how \texttt{lm} simplifies the process of model fitting and parameter estimation. Finally, we will assess the quality of the regression and use residual diagnostic plots to assess the validity of the regression assumptions.

\vspace{0.2cm}
\textbf{Part 1: The \texttt{faithful} Data Set}
\vspace{0.2cm}

In this section, we will perform regression-related EDA, fit a simple linear regression (SLR) model, and test the assumptions of the model. We will do all this using the \texttt{faithful} data set we last looked at in Workshop 4.

\vspace{0.2cm}

\textbf{1.1 Elementary Data Analysis/Correlation}

It is good practice to take a quick visual look at the data you will be using in your models.
\begin{enumerate}
\item Are there outliers in either column of the data? Generate boxplots to check.
\item To save typing later, let’s extract the columns into two variables. Create a vector \texttt{w} that contains the vector of waiting times, and a second vector \texttt{d} that contains the durations of eruptions.
\item Plot the waiting times (y-axis) against the durations (x-axis). Is there evidence of a linear relationship? Use the \texttt{cor} function to assess the strength of that linear relationship.
\item Is the \texttt{cor} function what we want to use here? Check if the values in each of the two variables are normally distributed.
\item Use the \texttt{method=``spearman''} argument inside the \texttt{cor} function to generate the Spearman's rank correlation coefficient.
\item Find the Kendall's tau correlation coefficient.

(Note that here we are simply checking there is any point to applying simple linear regression at all. Next week, when we consider multiple linear regressions, we tend to look at pairs of predictor variables using a scatter diagram, this time hoping we \textbf{don't} see much in the way of a linear relationship.)
\end{enumerate} 

\newpage

\textbf{1.2 The Linear Regression Model}

The model we’re interested in fitting to these data is a simple linear relationship between the waiting times, \texttt{w},
and the eruption durations, \texttt{d}. The model equation is
\begin{eqnarray*}
w=\beta_0+\beta_1d+\epsilon
\end{eqnarray*}

The \texttt{lm} function in \texttt{R} computes the least-squares linear regression for us, and returns an object which summarises all aspects of the regression fit.

Suppose our response variable is $Y$, and we have a predictor variable $X$, with observations stored in \texttt{R} as the vectors \texttt{y} and \texttt{x} respectively. To fit \texttt{y} as a linear function of \texttt{x}, we use the following command:

\texttt{model $<$- lm(y $\sim$ x)}

Alternatively, if we have a data frame called \texttt{dataset} with variables in columns named \texttt{``a''} and \texttt{``b''} then we could fit the linear regression of a on b without having to extract the columns into vectors.  Note the terminology here: ``a on b''. This means using a as the response, and b as the predictor. If a was being used as the predictor, we would say we were ``fitting b on a''.



We do this by specifying a data argument:

\texttt{model $<$- lm(a $\sim$ b, data=dataset)}

The tilde symbol (the ``$\sim$'' symbol) in this expression should be read as “is modelled as”. Note that \texttt{R} always automatically include a y-intercept (though you can tell \texttt{R} not to do so, if for some reason that's important), so we only need to specify the $X$
 and $Y$
 variables. 

We can inspect the fitted regression object returned from \texttt{lm} to get a simple summary of the estimated model parameters. To do this, simply enter the name of your model into \texttt{R}.








\begin{enumerate}
\item[7] Use \texttt{lm} to fit waiting times \texttt{w} as a linear function of eruption durations d. Save the result of the regression function to model.
\item[8] Note the values of the coefficients (the y-intercept and gradient given). What meaning can be taken from these values, given the meaning of the predictor and response variables?
\end{enumerate} 

\texttt{R} also has a number of functions that, when applied to the results of a linear regression, will return key quantities such as residuals and fitted values:

\vspace{0.35cm}

\texttt{coef(model)} and \texttt{coefficicents(model)} will return the estimated model coefficients as a vector $(b_0,b_1)$.

\texttt{fitted(model)} and \texttt{fitted.values(model)} will return the vector of fitted values, $\hat{y}_i=b_0+b_1x_i$.

\texttt{resid(model)} and \texttt{residuals(model)} will return the vector of residual values, $e_i=y_i−\hat{y}_i$.ˆ

\begin{enumerate}
    \item[9] Use the \texttt{coef} function to extract the coefficients of the fitted linear regression model as a vector.
\item[10]Extract the vector of residuals from model, and use this to compute the sum of squares of the residuals as \texttt{lsq.Q}.
\end{enumerate}   

We can easily extract and inspect the coefficients and residuals of the linear model, but to obtain a more complete statistical summary of the model we use the \texttt{summary} function: \texttt{summary(model)}

There is a lot of information in this output, but the key quantities to focus on today are:
\begin{itemize}
\item Residuals: simple summary statistics of the residuals from the regression.
\item Coefficients: a table of information about the fitted coefficients. Its columns are:
The label of the fitted coefficient: The first will usually be (Intercept), and subsequent rows will be named after the other predictor variables in the model.
\item The Estimate column gives the least squares estimates of the coefficients.
\item Residual standard error: This gives se
 the square root of the unbiased estimate of the residual variance.
\item Multiple R-Squared: This is the R2
 value defined in lectures as the squared correlation coefficient and is a measure of goodness of fit.    
\end{itemize}
We will consider the remaining values in next week's workshop.

We can also use the summary to access the individual elements of the regression summary output. If we save the results of a call to the summary function of a \texttt{lm} object as summ:

\vspace{0.35cm}

\texttt{summ\$residuals} extracts the regression residuals as \texttt{resid} above.

\texttt{summ\$coefficients} returns the $p\times4$
 coefficient summary table with columns for the estimated coefficient, its standard error, t-statistic and corresponding (two-sided) p-value (again, we'll take a closer look at this next week).
 
\texttt{summ\$sigma} extracts the regression standard error.

\texttt{R}'s estimate for the standard deviation of the errors in the model.

\texttt{summ\$r.squared} returns the coefficient of determination $R^2$.

\begin{enumerate}
\item[11] Apply the summary function to model to produce the regression summary for our example.

\item[12] Use the summary to find the coefficient estimates, the residual standard error, and the coefficient of determination $R^2$.

\item[13] Extract the value of $R^2$ from the \texttt{summary} output as a new variable. What does the value of $R^2$ here tell us about the fitted linear model?
\end{enumerate}

\textbf{Part 1.3 Checking Assumptions}

In this final section, we will use the \texttt{plot} function to check whether the four assumptions for a simple linear regression model hold for the model we have generated. We will also consider whether there are any points in the model which have high influence.

\begin{enumerate}
\item[14] Enter your model into the \texttt{plot} function. Remember that the function will cycle through four plots, and that you have to click on the plot window each time to get the next one.
\item[15] Evaluate assumptions one, two and four using the first three plots.
\item [16] Identify which points have high leverage using the fourth plot. Try removing these points from the data and recalculating the model. Does this make any difference to a) the performance of the model, b) the extent to which you believe the model assumptions hold?
\item Evaluate assumption three by calculating the autocorrelation of the residuals. Does our assumption of independence hold?
\end{enumerate}
 Once you have finished Part 1.3, you should feel free to spend the remainder of Workshop 5 working on your group mini-project.
\end{document}